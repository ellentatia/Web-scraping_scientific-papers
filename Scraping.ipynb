{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the Journal to find papers urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import urllib\n",
    "import urllib2\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URL you want to webscrape from\n",
    "url = 'https://link.springer.com/search?facet-journal-id=10666&query=valuation&facet-content-type=%22Article%22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the URL\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML and save to BeautifulSoup object\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the papers url on the website\n",
    "link = soup.find_all('a', href=True)\n",
    "#add the head of the urls in order to open them\n",
    "head = 'https://link.springer.com'\n",
    "urls=[]\n",
    "for links in link:\n",
    "    if links['href'].startswith('/article'):\n",
    "        urls.append(str(head + links['href']))\n",
    "print(urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the texts from the papers urls\n",
    "\n",
    "url1= urls[0]\n",
    "\n",
    "r=requests.get(url1)\n",
    "html_doc=r.text\n",
    "soup2=BeautifulSoup(html_doc,features=\"html.parser\") # add features=\"html.parser\"\n",
    "# by inspecting the elements we can observe that the p appears when there is a text, therefore let's find all 'p'\n",
    "texts= soup2.find_all('p')\n",
    "\n",
    "for text in texts:\n",
    "    content=str(text.getText())\n",
    "    #print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new file to store information\n",
    "secondfile = open('file2.txt', \"w\")\n",
    "#store all information of the file we have read \n",
    "for info in content:\n",
    "    secondfile.write(info + '\\n')\n",
    "#close the file\n",
    "secondfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save as txt \n",
    "def download_file_information(url):\n",
    "    #open the url file\n",
    "    fileOpen = urllib2.urlopen(url)\n",
    "    #read the file\n",
    "    file_info = fileOpen.read()\n",
    "    #convert into string\n",
    "    file_info_str=str(file_info)\n",
    "    #split the lines into the file\n",
    "    file_lines = file_info_str.split('\\\\n')\n",
    "    \n",
    "    #creating a new file to store information\n",
    "    newfile = open('file.txt', \"w\")\n",
    "    #store all information of the file we have read \n",
    "    for info in file_lines:\n",
    "        newfile.write(info + '\\n')\n",
    "    #close the file\n",
    "    newfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_information(urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    download_file_information(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
